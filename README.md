# ü¶† Syst√®me d'Extraction et d'Analyse d'Articles sur les Maladies Animales

> Application Python automatis√©e pour l'extraction, le traitement et l'analyse d'articles de presse multilingues sur les maladies animales, avec g√©n√©ration automatique de r√©sum√©s et extraction d'informations structur√©es.

## üìã Table des Mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Architecture](#architecture)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Structure des Donn√©es](#structure-des-donn√©es)
- [Technologies](#technologies)
- [Flux de Travail](#flux-de-travail)
- [D√©pannage](#d√©pannage)

---

## üéØ Vue d'ensemble

Ce projet est un syst√®me complet d'extraction et d'analyse d'articles de presse sur les maladies animales. Il permet de :

- **Extraire automatiquement** le contenu d'articles depuis des URLs
- **D√©tecter et traiter** plusieurs langues (Fran√ßais, Anglais, Arabe)
- **Extraire des informations structur√©es** : maladies, animaux, lieux, dates, organismes
- **G√©n√©rer des r√©sum√©s multilingues** de diff√©rentes longueurs (50, 100, 150 mots)
- **Nettoyer et normaliser** les donn√©es pour l'analyse

### Cas d'usage

- Surveillance √©pid√©miologique des maladies animales
- Veille sanitaire internationale
- Analyse de donn√©es pour tableaux de bord (Power BI, Excel)
- Recherche acad√©mique sur les maladies animales
- Collecte automatis√©e d'informations sanitaires

---

## ‚ú® Fonctionnalit√©s

### üîç Extraction Automatique
- Extraction de contenu depuis des URLs (articles de presse, sites officiels)
- D√©tection automatique de la langue (Fran√ßais, Anglais, Arabe)
- Extraction de m√©tadonn√©es (titre, contenu, date de publication)
- Gestion des erreurs d'extraction (sites inaccessibles, pages prot√©g√©es)

### üåç Multilingue
- **Fran√ßais** : Traitement natif avec Ollama
- **Anglais** : Traitement natif avec Ollama
- **Arabe** : Traitement avec support RTL, traduction optionnelle

### ü§ñ Intelligence Artificielle
- Utilisation d'**Ollama** (LLM local) pour l'extraction d'informations
- G√©n√©ration de r√©sum√©s contextuels multilingues
- Extraction intelligente d'entit√©s nomm√©es (maladies, animaux, lieux, organismes)
- Validation et nettoyage automatique des donn√©es

### üìä Extraction d'Informations Structur√©es
- **Maladies** : D√©tection et normalisation (ex: "rage", "fi√®vre aphteuse", "dermatose nodulaire")
- **Animaux** : Identification des esp√®ces concern√©es (bovins, ovins, volailles, etc.)
- **Lieux** : Extraction g√©ographique (pays, r√©gions, villes)
- **Dates** : D√©tection et normalisation des dates de publication
- **Organismes** : Identification des sources officielles (OMS, FAO, minist√®res, etc.)

### üìù G√©n√©ration de R√©sum√©s
- R√©sum√©s de **50 mots** : Vue d'ensemble concise
- R√©sum√©s de **100 mots** : Informations d√©taill√©es
- R√©sum√©s de **150 mots** : Contenu complet
- G√©n√©ration parall√®le pour performance optimale

### üßπ Nettoyage de Donn√©es
- Remplacement des valeurs manquantes par "non d√©tect√©"
- Normalisation des erreurs ("unknown" ‚Üí "non d√©tect√©")
- Gestion des erreurs d'extraction ("Erreur d'extraction" ‚Üí "site inaccessible")
- Validation de la coh√©rence des donn√©es

---

## üèóÔ∏è Architecture

### Structure du Projet

```
.
‚îú‚îÄ‚îÄ src/                          # Modules Python (code source)
‚îÇ   ‚îú‚îÄ‚îÄ extraction_complete.py    # Module principal d'extraction
‚îÇ   ‚îú‚îÄ‚îÄ resumes.py                # Module de g√©n√©ration de r√©sum√©s
‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py           # Client pour l'API Ollama
‚îÇ   ‚îú‚îÄ‚îÄ translator.py             # Module de traduction
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py                # Gestionnaire de prompts pour LLM
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                  # Fonctions utilitaires
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Scripts d'ex√©cution
‚îÇ   ‚îú‚îÄ‚îÄ run_extraction.py         # Script pour lancer l'extraction
‚îÇ   ‚îú‚îÄ‚îÄ run_summaries.py          # Script pour g√©n√©rer les r√©sum√©s
‚îÇ   ‚îî‚îÄ‚îÄ clean_data.py             # Script de nettoyage des donn√©es
‚îÇ
‚îú‚îÄ‚îÄ config/                       # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ config_ia.py              # Configuration IA (Ollama, mod√®les)
‚îÇ   ‚îî‚îÄ‚îÄ data_constants.py          # Constantes et mappings de donn√©es
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Donn√©es (CSV)
‚îÇ   ‚îú‚îÄ‚îÄ input_urls.csv            # URLs sources √† traiter
‚îÇ   ‚îú‚îÄ‚îÄ extracted_articles.csv    # Articles extraits avec m√©tadonn√©es
‚îÇ   ‚îú‚îÄ‚îÄ summarized_articles.csv   # Articles avec r√©sum√©s g√©n√©r√©s
‚îÇ   ‚îî‚îÄ‚îÄ final_dataset.csv         # Dataset final nettoy√©
‚îÇ
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îú‚îÄ‚îÄ venv/                         # Environnement virtuel Python
‚îú‚îÄ‚îÄ requirements.txt              # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                     # Ce fichier
```

### Composants Principaux

#### 1. **NewsExtractor** (`src/extraction_complete.py`)
Classe principale pour l'extraction d'informations depuis les URLs :
- Extraction de contenu avec Trafilatura
- D√©tection de langue avec LangDetect
- Extraction de dates avec HTMLDate et DateParser
- Extraction d'entit√©s avec Ollama (maladies, animaux, lieux, organismes)
- Validation et nettoyage du contenu

#### 2. **R√©sum√©s** (`src/resumes.py`)
Module de g√©n√©ration de r√©sum√©s multilingues :
- G√©n√©ration parall√®le avec ThreadPoolExecutor
- Support multilingue (FR, EN, AR)
- Trois longueurs de r√©sum√©s (50, 100, 150 mots)
- Gestion des erreurs et retry automatique

#### 3. **OllamaClient** (`src/ollama_client.py`)
Client pour interagir avec l'API Ollama :
- D√©tection automatique du mod√®le install√©
- Gestion des timeouts et retry
- Support de diff√©rents mod√®les (phi3:mini, llama2, mistral, etc.)

#### 4. **PromptManager** (`src/prompts.py`)
Gestionnaire centralis√© des prompts :
- Prompts pour extraction de dates
- Prompts pour extraction de maladies
- Prompts pour extraction d'animaux
- Prompts pour extraction de lieux
- Prompts pour extraction d'organismes

#### 5. **Utils** (`src/utils.py`)
Fonctions utilitaires :
- Nettoyage de contenu (suppression menus, publicit√©s)
- Calcul de statistiques (caract√®res, mots)
- Validation de coh√©rence contenu/titre

---

## üöÄ Installation

### Pr√©requis

- **Python 3.10+** (recommand√© : Python 3.10 ou 3.11)
- **Ollama** (pour l'IA locale) - [T√©l√©charger](https://ollama.ai)
- **Git** (optionnel, pour cloner le projet)

### √âtapes d'Installation

#### 1. Cloner ou t√©l√©charger le projet

```bash
# Si vous utilisez Git
git clone <url-du-repo>
cd <nom-du-projet>

# Ou simplement extraire l'archive ZIP
```

#### 2. Cr√©er un environnement virtuel

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

#### 4. Installer Ollama

1. T√©l√©charger Ollama depuis [https://ollama.ai](https://ollama.ai)
2. Installer et lancer Ollama
3. T√©l√©charger un mod√®le (recommand√© : `phi3:mini` pour la rapidit√©)

```bash
# Mod√®les recommand√©s (du plus rapide au plus performant)
ollama pull phi3:mini      # ~2.2GB - Rapide et efficace ‚úÖ RECOMMAND√â
ollama pull llama3.2       # ~2GB - √âquilibr√©
ollama pull llama2         # ~3.8GB - Plus performant
ollama pull mistral        # ~4.1GB - Tr√®s performant
```

#### 5. V√©rifier l'installation

```bash
# V√©rifier que Ollama fonctionne
ollama list

# Tester un mod√®le
ollama run phi3:mini "Bonjour"
```

---

## ‚öôÔ∏è Configuration

### Configuration de l'IA (`config/config_ia.py`)

```python
# Activer/d√©sactiver Ollama
USE_OLLAMA = True

# Mod√®le Ollama √† utiliser
OLLAMA_MODEL = "phi3:mini"  # Modifier selon votre mod√®le install√©
```

**Mod√®les recommand√©s :**
- `phi3:mini` : Rapide (~2.2GB), bon pour la production
- `llama3.2` : √âquilibr√© (~2GB), bon compromis
- `llama2` : Performant (~3.8GB), meilleure qualit√©
- `mistral` : Tr√®s performant (~4.1GB), meilleure qualit√©

### Constantes de Donn√©es (`config/data_constants.py`)

Ce fichier contient :
- **Listes de lieux** : Pays, villes, r√©gions (multilingue)
- **Dictionnaires d'animaux** : Mappings multilingues (FR, EN, AR)
- **Patterns de validation** : Regex pour extraction et validation
- **Mappings de traduction** : Correspondances entre langues

**Note** : Modifier ce fichier uniquement si vous souhaitez ajouter des lieux, animaux ou patterns personnalis√©s.

---

## üìñ Utilisation

### Pr√©paration des Donn√©es

1. **Cr√©er le fichier d'entr√©e** `data/input_urls.csv` :

```csv
Code,URL
code001,https://example.com/article1
code002,https://example.com/article2
code003,https://example.com/article3
```

**Format requis :**
- Colonne `Code` : Identifiant unique de l'article
- Colonne `URL` : URL de l'article √† traiter

### √âtape 1 : Extraction de Contenu

Extrait le contenu des articles depuis les URLs.

```bash
# M√©thode recommand√©e (via script)
python scripts/run_extraction.py

# M√©thode alternative (directement)
python src/extraction_complete.py
```

**R√©sultat :** G√©n√®re `data/extracted_articles.csv` avec :
- Titre, contenu, langue d√©tect√©e
- Date de publication
- Maladie, animal, lieu, organisme (si d√©tect√©s)
- Statistiques (caract√®res, mots)
- Erreurs √©ventuelles

**Dur√©e estim√©e :** ~2-5 secondes par article (selon la complexit√© et le mod√®le Ollama)

### √âtape 2 : G√©n√©ration de R√©sum√©s

G√©n√®re les r√©sum√©s multilingues pour chaque article.

```bash
# M√©thode recommand√©e (via script)
python scripts/run_summaries.py

# M√©thode alternative (directement)
python src/resumes.py
```

**R√©sultat :** G√©n√®re `data/summarized_articles.csv` avec :
- `resum_50` : R√©sum√© de 50 mots
- `resum_100` : R√©sum√© de 100 mots
- `resum_150` : R√©sum√© de 150 mots

**Dur√©e estim√©e :** ~3-10 secondes par article (selon le mod√®le Ollama et la longueur)

### √âtape 3 : Nettoyage des Donn√©es (Optionnel)

Nettoie et normalise les donn√©es pour l'analyse.

```bash
python scripts/clean_data.py
```

**R√©sultat :** G√©n√®re `data/final_dataset.csv` avec :
- Valeurs manquantes remplac√©es par "non d√©tect√©"
- "unknown" remplac√© par "non d√©tect√©"
- "Erreur d'extraction" remplac√© par "site inaccessible"
- Donn√©es pr√™tes pour l'analyse

**Dur√©e estim√©e :** < 1 seconde (tr√®s rapide)

---

## üìä Structure des Donn√©es

### Fichier d'Entr√©e : `input_urls.csv`

```csv
Code,URL
code001,https://example.com/article1
code002,https://example.com/article2
```

### Fichier Interm√©diaire : `extracted_articles.csv`

Colonnes principales :
- `Code` : Identifiant unique
- `URL` : URL source
- `Titre` : Titre de l'article
- `Contenu` : Contenu complet extrait
- `Langue` : Langue d√©tect√©e (fr, en, ar)
- `Date_Publication` : Date au format YYYY-MM-DD
- `Lieu` : Lieu g√©ographique d√©tect√©
- `Maladie` : Maladie d√©tect√©e
- `Animal` : Animal concern√©
- `Organisme` : Organisme source
- `Source` : Type de source (m√©dias, site officiel)
- `Caracteres` : Nombre de caract√®res
- `Mots` : Nombre de mots
- `Erreur` : Message d'erreur si applicable

### Fichier avec R√©sum√©s : `summarized_articles.csv`

Contient toutes les colonnes de `extracted_articles.csv` plus :
- `resum_50` : R√©sum√© de 50 mots
- `resum_100` : R√©sum√© de 100 mots
- `resum_150` : R√©sum√© de 150 mots

### Fichier Final : `final_dataset.csv`

Version nettoy√©e de `summarized_articles.csv` avec :
- Toutes les valeurs manquantes normalis√©es
- Erreurs d'extraction g√©r√©es
- Donn√©es pr√™tes pour l'analyse

---

## üõ†Ô∏è Technologies

### Biblioth√®ques Python Principales

- **pandas** : Manipulation et analyse de donn√©es
- **requests** : Requ√™tes HTTP pour Ollama
- **trafilatura** : Extraction de contenu web
- **beautifulsoup4** : Parsing HTML
- **langdetect** : D√©tection automatique de langue
- **htmldate** : Extraction de dates depuis HTML
- **dateparser** : Parsing flexible de dates
- **transformers** : Mod√®les NLP (optionnel, pour r√©sum√©s avanc√©s)
- **torch** : Backend pour transformers
- **tqdm** : Barres de progression

### Intelligence Artificielle

- **Ollama** : LLM local pour extraction et r√©sum√©s
  - Mod√®les support√©s : phi3:mini, llama2, llama3.2, mistral
  - API REST locale (http://localhost:11434)
  - Gratuit et sans limite d'utilisation

### Outils d'Extraction

- **Trafilatura** : Extraction de contenu principal (article)
- **BeautifulSoup** : Parsing HTML avanc√©
- **HTMLDate** : Extraction de dates depuis m√©tadonn√©es HTML
- **DateParser** : Parsing flexible de dates multilingues

---

## üîÑ Flux de Travail

```mermaid
graph TD
    A[input_urls.csv] --> B[Extraction]
    B --> C[extracted_articles.csv]
    C --> D[G√©n√©ration R√©sum√©s]
    D --> E[summarized_articles.csv]
    E --> F[Nettoyage]
    F --> G[final_dataset.csv]
    G --> H[Analyse / Power BI]
```

### Processus D√©taill√©

1. **Input** : Fichier CSV avec URLs
2. **Extraction** :
   - R√©cup√©ration du contenu depuis chaque URL
   - D√©tection de la langue
   - Extraction de m√©tadonn√©es (date, titre)
   - Extraction d'entit√©s avec Ollama (maladie, animal, lieu, organisme)
3. **R√©sum√©s** :
   - G√©n√©ration de 3 r√©sum√©s par article (50, 100, 150 mots)
   - Traitement parall√®le pour performance
4. **Nettoyage** :
   - Normalisation des valeurs manquantes
   - Gestion des erreurs
   - Validation de coh√©rence
5. **Output** : Dataset final pr√™t pour l'analyse

---

## üîß D√©pannage

### Probl√®mes Courants

#### Ollama ne r√©pond pas

```bash
# V√©rifier que Ollama est lanc√©
ollama list

# Red√©marrer Ollama
# Windows : Red√©marrer le service Ollama
# Linux/Mac : ollama serve
```

#### Erreur "Model not found"

```bash
# V√©rifier les mod√®les install√©s
ollama list

# Installer le mod√®le configur√©
ollama pull phi3:mini
```

#### Erreurs d'extraction fr√©quentes

- V√©rifier la connectivit√© internet
- Certains sites peuvent bloquer les scrapers
- V√©rifier que les URLs sont accessibles manuellement

#### Performance lente

- Utiliser un mod√®le plus rapide (`phi3:mini` au lieu de `llama2`)
- R√©duire le nombre de workers dans `resumes.py` (MAX_WORKERS)
- V√©rifier les ressources syst√®me (RAM, CPU)

#### Probl√®mes de m√©moire

- R√©duire MAX_WORKERS dans `resumes.py`
- Utiliser un mod√®le plus petit (`phi3:mini`)
- Traiter les donn√©es par lots

### Logs et Debugging

Les scripts affichent des messages de progression :
- `[OK]` : Succ√®s
- `[ATTENTION]` : Avertissement (non bloquant)
- `[ERREUR]` : Erreur (bloquant)

Pour plus de d√©tails, consulter les messages dans la console.

---

## üìù Notes Importantes

### Limitations

- **D√©pendance Ollama** : N√©cessite Ollama install√© et lanc√© localement
- **Performance** : La vitesse d√©pend du mod√®le Ollama utilis√©
- **Extraction** : Certains sites peuvent bloquer les scrapers
- **Langues** : Support optimal pour FR, EN, AR. Autres langues avec d√©tection automatique

### Bonnes Pratiques

1. **Tester avec un petit √©chantillon** avant de traiter de grandes quantit√©s
2. **Sauvegarder r√©guli√®rement** les fichiers interm√©diaires
3. **V√©rifier la qualit√©** des extractions avant de g√©n√©rer les r√©sum√©s
4. **Utiliser un mod√®le adapt√©** √† vos besoins (rapidit√© vs qualit√©)

### Support

Pour toute question ou probl√®me :
1. V√©rifier la section [D√©pannage](#d√©pannage)
2. Consulter les logs d'erreur
3. V√©rifier la configuration dans `config/config_ia.py`

---

## üìÑ Licence

[√Ä compl√©ter selon votre licence]

---

## üë• Auteurs

[√Ä compl√©ter]

---

## üôè Remerciements

- **Ollama** pour l'infrastructure LLM locale
- **Trafilatura** pour l'extraction de contenu
- **Communaut√© Python** pour les excellentes biblioth√®ques

---

**Derni√®re mise √† jour :** D√©cembre 2025
